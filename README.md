# Damkar Samarinda - SK Document Processing & AI Agent

Sistem pemrosesan dokumen Surat Keputusan (SK) untuk Dinas Pemadam Kebakaran dan Penyelamatan Kota Samarinda dengan AI Agent yang dapat berinteraksi menggunakan bahasa natural.

## ğŸ”¥ Overview

Project ini terdiri dari dua komponen utama:
1. **Airflow Pipeline** - Untuk extract, transform, dan load dokumen SK ke Neo4j
2. **AI Agent** - Interface natural language untuk query dan analisis data SK

## ğŸ—ï¸ Arsitektur Sistem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Files     â”‚    â”‚  Airflow Pipeline â”‚    â”‚    Neo4j DB     â”‚
â”‚   (SK Documents)â”‚â”€â”€â”€â–¶â”‚  - Extract Text   â”‚â”€â”€â”€â–¶â”‚   (damkar-sk)   â”‚
â”‚                 â”‚    â”‚  - Parse Data     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  - Load to Neo4j  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                         â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
                       â”‚   AI Agent       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚  - Natural Lang  â”‚
                       â”‚  - Query Neo4j   â”‚
                       â”‚  - Smart Analysisâ”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

### Airflow Pipeline
- âœ… **Agentic PDF Processing** - Extract informasi pegawai dari dokumen SK
- âœ… **Data Replacement** - Clear existing data sebelum load baru
- âœ… **Chunked Processing** - Process data dalam chunk 100 record
- âœ… **Error Handling** - Robust error handling dan logging
- âœ… **Multi-format Support** - Support PNS dan PPPK documents

### AI Agent
- âœ… **Natural Language Interface** - Query dalam bahasa Indonesia
- âœ… **Smart Query Processing** - Convert natural language ke Cypher
- âœ… **Interactive Mode** - Real-time conversation interface
- âœ… **Multiple Query Types** - Search, statistics, listing, overview
- âœ… **Performance Optimized** - Fast query execution dan caching

## ğŸ“‹ Prerequisites

### System Requirements
- Docker & Docker Compose
- Python 3.8+
- Neo4j Database
- 4GB+ RAM
- 10GB+ Disk Space

### Dependencies
```bash
# Python packages
neo4j>=5.0.0
pdfplumber>=4.0.0
apache-airflow>=2.7.0
```

## ğŸ› ï¸ Installation

### 1. Clone Repository
```bash
git clone https://github.com/yourusername/damkar-samarinda-sk.git
cd damkar-samarinda-sk
```

### 2. Environment Setup
```bash
# Copy environment template
cp .env.example .env

# Edit environment variables
export NEO4J_URI="neo4j://localhost:7687"
export NEO4J_USER="neo4j"
export NEO4J_PASSWORD="your-password"
export NEO4J_DATABASE="damkar-sk"
```

### 3. Start Services
```bash
# Start Airflow with Neo4j
docker-compose -f docker-compose-neo4j-fixed.yml up -d

# Or start Neo4j separately
docker run -d --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/your-password \
  -e NEO4J_PLUGINS='["apoc"]' \
  neo4j:latest
```

### 4. Install Python Dependencies
```bash
pip install neo4j pdfplumber python-dotenv
```

## ğŸ“Š Usage

### Airflow Pipeline

1. **Access Airflow Web UI**
   ```
   http://localhost:8080
   Username: airflow
   Password: airflow
   ```

2. **Run PDF Processing DAG**
   - Navigate to `agentic_pdf_processing_dag`
   - Click "Trigger DAG"
   - Monitor progress in real-time

3. **DAG Features**
   - **Extract Task**: Scan dan extract text dari PDF files
   - **Analysis Task**: Parse dan structure data pegawai
   - **Load Task**: Load data ke Neo4j dengan chunking

### AI Agent

#### Interactive Mode
```bash
python damkar_sk_agent.py
```

```
ğŸ¤– Damkar SK Agent - Interactive Mode
==================================================
ğŸ’¬ Query: cari SABARUDDIN

ğŸ“Š Found 1 records
â±ï¸ Execution time: 0.37s
--------------------------------------------------
1. nama: SABARUDDIN | nip: 1971060320070110383 | 
   institusi: Pemerintah Kota Samarinda | 
   unit_kerja: Dinas Pemadam Kebakaran dan Penyelamatan
```

#### Programmatic Usage
```python
from damkar_sk_agent import DamkarSKAgent

# Initialize agent
agent = DamkarSKAgent()

# Query pegawai
result = agent.process_natural_language_query("cari SABARUDDIN")
print(agent.format_results(result))

# Statistics
result = agent.process_natural_language_query("berapa jumlah pegawai")
print(agent.format_results(result))

agent.close()
```

### Query Examples

#### Basic Queries
```
cari SABARUDDIN              # Cari pegawai spesifik
daftar pegawai PNS          # List semua PNS
daftar pegawai PPPK         # List semua PPPK  
semua pegawai               # List semua pegawai
```

#### Statistics & Analysis
```
berapa jumlah pegawai       # Total pegawai
statistik pegawai           # Statistik berdasarkan jenis SK
statistik unit kerja        # Statistik per unit kerja
overview                    # Ringkasan database
```

## ğŸ—‚ï¸ Project Structure

```
airflow-lightweight/
â”œâ”€â”€ dags/                              # Airflow DAGs
â”‚   â”œâ”€â”€ agentic_pdf_processing_dag.py  # Main PDF processing pipeline
â”‚   â”œâ”€â”€ hello_world_dag.py             # Test DAG
â”‚   â””â”€â”€ pdf_to_neo4j_*.py             # Alternative pipelines
â”œâ”€â”€ data/                              # PDF documents (gitignored)
â”‚   â”œâ”€â”€ SK PNS/                       # PNS appointment documents
â”‚   â””â”€â”€ SK PPPK/                      # PPPK appointment documents
â”œâ”€â”€ logs/                              # Airflow logs (gitignored)
â”œâ”€â”€ plugins/                           # Airflow plugins
â”œâ”€â”€ damkar_sk_agent.py                 # AI Agent main file
â”œâ”€â”€ test_damkar_agent.py              # Agent test suite
â”œâ”€â”€ example_usage.py                  # Usage examples
â”œâ”€â”€ debug_schema.py                   # Database schema debugging
â”œâ”€â”€ docker-compose-neo4j-fixed.yml   # Docker compose configuration
â”œâ”€â”€ README_DAMKAR_AGENT.md           # Agent documentation
â”œâ”€â”€ cypher_queries_with_sk_dates.md  # Cypher query examples
â””â”€â”€ requirements.txt                  # Python dependencies
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Neo4j Configuration
NEO4J_URI=neo4j://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-password
NEO4J_DATABASE=damkar-sk

# Airflow Configuration  
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=4
AIRFLOW__CORE__PARALLELISM=4
AIRFLOW__WEBSERVER__WORKERS=2
```

### Docker Compose Override
Create `docker-compose.override.yml` for custom configurations:
```yaml
version: '3.8'
services:
  airflow-webserver:
    environment:
      - CUSTOM_ENV_VAR=value
    ports:
      - "8081:8080"  # Custom port
```

## ğŸ—„ï¸ Database Schema

### Neo4j Graph Model
```cypher
# Nodes
(Person {name, employee_id, institution, work_unit, created_at})
(Document {document_type, file_path, processing_timestamp, created_at})

# Relationships  
(Person)-[:HAS_DOCUMENT]->(Document)
```

### Sample Data
```cypher
MATCH (p:Person)-[:HAS_DOCUMENT]->(d:Document)
RETURN p.name as nama, p.employee_id as nip, 
       p.work_unit as unit_kerja, d.document_type as jenis_sk
LIMIT 5
```

## ğŸ§ª Testing

### Run Test Suite
```bash
# Test database connection and basic queries
python test_damkar_agent.py

# Test with examples
python example_usage.py

# Debug database schema
python debug_schema.py
```

### Manual Testing
```bash
# Test Airflow DAG
curl -X POST http://localhost:8080/api/v1/dags/agentic_pdf_processing_dag/dagRuns \
  -H "Content-Type: application/json" \
  -d '{"conf": {}}'

# Test Neo4j connection
cypher-shell -u neo4j -p your-password -d damkar-sk "MATCH (n) RETURN count(n)"
```

## ğŸ“ˆ Performance

### Benchmarks
- **PDF Processing**: ~50 documents/minute
- **Query Response**: <1 second average
- **Memory Usage**: <2GB during processing
- **Database Size**: ~10MB for 100 documents

### Optimization Tips
```python
# For large datasets
agent = DamkarSKAgent()
agent.query_templates['batch_query'] = '''
    MATCH (p:Person)-[:HAS_DOCUMENT]->(d:Document)
    WHERE p.work_unit CONTAINS $unit
    RETURN p.name, p.employee_id
    ORDER BY p.name
    LIMIT 1000
'''
```

## ğŸ”’ Security

### Data Protection
- âœ… PDF files excluded from git
- âœ… Environment variables for credentials
- âœ… Database access controls
- âœ… Input validation for queries

### Best Practices
```bash
# Use strong passwords
export NEO4J_PASSWORD=$(openssl rand -base64 32)

# Restrict network access
# Configure firewall for ports 7687, 8080

# Regular backups
neo4j-admin dump --database=damkar-sk --to=backup.dump
```

## ğŸš¨ Troubleshooting

### Common Issues

#### 1. Connection Errors
```bash
# Check Neo4j status
docker logs neo4j

# Test connection
python -c "from neo4j import GraphDatabase; print('Connected' if GraphDatabase.driver('neo4j://localhost:7687', auth=('neo4j', 'password')).verify_connectivity() else 'Failed')"
```

#### 2. Airflow Issues
```bash
# Check Airflow logs
docker logs airflow-lightweight-airflow-webserver-1

# Restart services
docker-compose -f docker-compose-neo4j-fixed.yml restart
```

#### 3. Memory Issues
```bash
# Increase Docker memory limits
# Add to docker-compose.yml:
deploy:
  resources:
    limits:
      memory: 2G
```

#### 4. Performance Issues
```python
# Use connection pooling
driver = GraphDatabase.driver(uri, auth=auth, max_connection_pool_size=20)

# Enable query caching
session.run("CALL apoc.config.set('apoc.result.stream', 'true')")
```

## ğŸ¤ Contributing

### Development Setup
```bash
# Fork repository
git clone https://github.com/yourusername/damkar-samarinda-sk.git

# Create feature branch
git checkout -b feature/new-feature

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
python -m pytest tests/

# Commit changes
git commit -m "Add new feature"
git push origin feature/new-feature
```

### Code Style
```bash
# Format code
black *.py

# Lint code  
flake8 *.py

# Type checking
mypy *.py
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Dinas Pemadam Kebakaran dan Penyelamatan Kota Samarinda** - Data dan requirements
- **Apache Airflow Community** - Workflow management
- **Neo4j Community** - Graph database platform
- **Python Community** - Libraries dan tools

## ğŸ“ Support

### Documentation
- [Airflow Documentation](https://airflow.apache.org/docs/)
- [Neo4j Documentation](https://neo4j.com/docs/)
- [Agent Usage Guide](README_DAMKAR_AGENT.md)

### Contact
- **Project Maintainer**: Your Name
- **Email**: your.email@example.com
- **GitHub Issues**: [Create Issue](https://github.com/yourusername/damkar-samarinda-sk/issues)

---

**ğŸ”¥ Damkar Samarinda SK Processing System** - Transforming document management with AI-powered automation.